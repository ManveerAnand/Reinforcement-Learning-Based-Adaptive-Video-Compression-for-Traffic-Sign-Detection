# ğŸ¯ RL-Based Adaptive Video Compression for Traffic Sign Detection

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5.1-red.svg)](https://pytorch.org/)
[![YOLOv8](https://img.shields.io/badge/YOLOv8n-Ultralytics-green.svg)](https://github.com/ultralytics/ultralytics)
[![CUDA](https://img.shields.io/badge/CUDA-12.1-green.svg)](https://developer.nvidia.com/cuda-toolkit)

## ğŸ“‹ Overview

This project implements an **RL-based adaptive video compression system** using **Snapshot Compressive Imaging (SCI)** for efficient traffic sign detection. The goal is to dynamically adjust compression ratios (B values) based on video content to maximize detection accuracy while minimizing bandwidth.

### Key Components
- **SCI Compression**: Binary mask-based snapshot compressive imaging (B âˆˆ {6,8,10,12,15,20})
- **YOLOv8n Detection**: Fine-tuned traffic sign detector on compressed measurements
- **RL Agent**: Adaptive B-value selection based on video characteristics (planned)

### Current Status
âœ… **Phase 1-5 Complete**: Dataset generation, YOLO training finished  
âœ… **RL Training**: 500 episodes, +9.0% improvement (45.48â†’49.58)  
âœ… **Experiment 1 Complete**: Fixed baseline (280 videos, 1682 results)  
ğŸ”„ **Experiment 2 Running**: Random policy with checkpoint system  
â³ **Experiment 3-4**: Package created for parallel execution  
ğŸ“‹ **Next**: Complete all benchmarking, statistical analysis, write paper

---

## ğŸš€ Quick Start

### Prerequisites
- **GPU**: NVIDIA GPU with 8GB+ VRAM (RTX 4060/3060 or better)
- **CUDA**: 12.1+
- **Python**: 3.12
- **Storage**: 50GB+ free space

### Environment Setup

```bash
# Create conda environment
conda create -n rl_video_compression python=3.12
conda activate rl_video_compression

# Install dependencies
pip install -r requirements.txt
```

### Training YOLOv8

```bash
cd training
python train_yolo_local.py
```

### Validation

```bash
cd training
python validate_yolo.py
```

---

## ğŸ“ Project Structure

```
RL_Video_Compression/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cure-tsd/              # Original CURE-TSD dataset
â”‚   â”‚   â”œâ”€â”€ data/              # Raw video frames
â”‚   â”‚   â””â”€â”€ labels/            # Ground truth annotations
â”‚   â”œâ”€â”€ masks/                 # Binary SCI masks (B=6,8,10,12,15,20)
â”‚   â””â”€â”€ yolo_dataset_full/     # Generated YOLO dataset
â”‚       â”œâ”€â”€ images/            # SCI compressed measurements (28,727 images)
â”‚       â”œâ”€â”€ labels/            # YOLO format labels
â”‚       â””â”€â”€ data.yaml          # Dataset config
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ phase1/                # Feature extraction & compression
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py
â”‚   â”‚   â”œâ”€â”€ label_parser.py
â”‚   â”‚   â”œâ”€â”€ sci_compressor.py
â”‚   â”‚   â””â”€â”€ video_loader.py
â”‚   â””â”€â”€ phase5/                # Dataset generation
â”‚       â”œâ”€â”€ dataset_builder.py
â”‚       â”œâ”€â”€ label_converter.py
â”‚       â””â”€â”€ measurement_generator.py
â”‚
â”œâ”€â”€ training/                  # Training scripts
â”‚   â”œâ”€â”€ train_yolo_local.py   # YOLOv8 training
â”‚   â”œâ”€â”€ validate_yolo.py      # Validation script
â”‚   â””â”€â”€ test_inference.py     # Inference testing
â”‚
â”œâ”€â”€ scripts/                   # Utility & experiment scripts
â”‚   â”œâ”€â”€ evaluate_fixed_baselines.py  # Experiment 1 (complete)
â”‚   â”œâ”€â”€ evaluate_random_policy.py    # Experiment 2 (running, with checkpoints)
â”‚   â”œâ”€â”€ evaluate_rl_agent.py         # Experiment 3 (ready)
â”‚   â”œâ”€â”€ statistical_tests.py         # Experiment 4 (ready)
â”‚   â”œâ”€â”€ generate_full_dataset.py
â”‚   â”œâ”€â”€ recover_dataset.py
â”‚   â”œâ”€â”€ check_dataset_progress.py
â”‚   â””â”€â”€ validate_remaining_experiments.py
â”‚
â”œâ”€â”€ outputs/                   # Experiment results
â”‚   â”œâ”€â”€ fixed_baseline_results.csv   # 1,682 rows (complete)
â”‚   â”œâ”€â”€ random_policy_checkpoint.json # Resume point
â”‚   â””â”€â”€ benchmarks/            # (reserved for final results)
â”‚
â”œâ”€â”€ runs/                      # Training outputs
â”‚   â”œâ”€â”€ rl_training/           # RL agent checkpoints
â”‚   â”‚   â”œâ”€â”€ best_model.pth     # Best RL agent (episode 500)
â”‚   â”‚   â””â”€â”€ checkpoint_ep*.pth # Training checkpoints
â”‚   â””â”€â”€ train/
â”‚       â””â”€â”€ yolo_cure_tsd/     # YOLO training run
â”‚           â”œâ”€â”€ weights/       # best.pt (83.29% mAP50)
â”‚           â””â”€â”€ results.csv    # Training metrics
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ PROJECT_STATUS.md     # Current progress (75% complete)
â”‚   â”œâ”€â”€ PAPER_OUTLINE.md      # Research paper structure
â”‚   â””â”€â”€ RESEARCH_PLAN.md      # Full research roadmap
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## ğŸ“ Dataset

**CURE-TSD** (Challenging Unreal and Real Environments - Traffic Sign Detection)

- **Size**: 1,805 videos, 14 traffic sign classes
- **Resolution**: 1628Ã—1236 pixels, 10 FPS
- **Current Progress**: 28,727 images from 1,561 videos (86.5% complete)
  - Training: 19,975 images (1,073 videos, 68.7%)
  - Validation: 8,752 images (488 videos, 31.3%)
- **Link**: [Georgia Tech OLIVES Lab](https://github.com/olivesgatech/CURE-TSD)

### Traffic Sign Classes (14 Total)
- Speed limits: 30, 60, 80, 100, 120 km/h
- Signs: Stop, Give way, No passing, Priority road, Priority at intersection, No passing trucks, End of restrictions, Roundabout, Crosswalk

---

## ğŸ”¬ Methodology

### 1. SCI Compression
Compresses B consecutive frames into a single measurement using binary masks:

```
Y = Î£(mask_i Ã— frame_i) for i = 1 to B
```

- **Compression Ratios**: B âˆˆ {6,8,10,12,15,20} â†’ 83-95% bandwidth savings
- **Masks**: Random binary patterns (1628Ã—1236)

### 2. YOLOv8n Detection
- **Architecture**: YOLOv8 Nano (3.0M parameters)
- **Training**: 100 epochs, batch=16, img=640, AdamW optimizer
- **Hardware**: RTX 4060 Laptop (8GB VRAM)
- **Performance**: 83.29% mAP50, 86.73% precision, 74.94% recall

### 3. RL Agent (Planned)
- **State**: Video features (optical flow, edge density, blur, etc.)
- **Action**: Select B âˆˆ {6,8,10,12,15,20}
- **Reward**: 0.7Ã—mAP + 0.3Ã—(B/20) - 2.0Ã—critical_misses
- **Algorithm**: DQN or PPO

---

## ğŸ“Š Results

### Benchmarking Progress (280 Validation Videos)

| Experiment | Status | Output | Notes |
|------------|--------|--------|-------|
| **1. Fixed Baselines** | âœ… Complete | `fixed_baseline_results.csv` (1,681 rows) | 6 B-values Ã— 280 videos |
| **2. Random Policy** | âœ… Complete | `random_policy_results.csv` (281 rows) | 280 videos (1 trial each) |
| **3. RL Agent** | ğŸ”„ Running | `rl_agent_results.csv` (280 rows) | DQN fixed, ready to execute |
| **4. Statistical Tests** | â³ Queued | `statistical_tests_results.json` | After Exp 3 complete |

**Experiment 1 Summary** (Fixed B-values):
- **B=6**: 85 detections avg, 83.3% bandwidth savings
- **B=10**: 63 detections avg, 90.0% bandwidth savings  
- **B=20**: 43 detections avg, 95.0% bandwidth savings
- **Trade-off**: Lower B = higher accuracy, Higher B = more savings

### RL Training Results (500 Episodes)

| Metric | Initial | Final | Improvement |
|--------|---------|-------|-------------|
| **Score** | 45.48 | 49.58 | +9.0% |
| **Avg B-value** | ~14 | 18.14 | Learned higher compression |
| **Training Time** | - | 3.35 hours | RTX 4060 Laptop |

**Key Features**:
- âœ… Checkpoint system implemented (auto-resume)
- âœ… Memory management (periodic garbage collection)
- âœ… Package system for distributed execution
- âœ… Statistical testing infrastructure ready

### YOLO Training Results (SCI-Compressed Data)

| Metric | Value |
|--------|-------|
| mAP50 | 83.29% |
| mAP50-95 | 47.44% |
| Precision | 86.73% |
| Recall | 74.94% |

### Per-Class Performance (Top 5)

| Class | mAP50 | Images |
|-------|-------|--------|
| No passing trucks | 93.1% | 241 |
| Speed limit 120 | 89.1% | 435 |
| Priority road | 85.6% | 1,254 |
| Speed limit 80 | 84.4% | 1,068 |
| Crosswalk | 83.7% | 1,028 |

### Training Details
- **Duration**: 100 epochs (~16 hours)
- **Best Epoch**: Epoch 84 (84.06% mAP50)
- **Final Loss**: box=1.18, cls=0.75, dfl=1.05
- **VRAM Usage**: 1.1-2.0 GB stable

---

## ğŸ› ï¸ Usage

### Running Benchmarking Experiments

**Prerequisites**:
```bash
conda activate rl_video_compression
export PYTHONPATH="/path/to/RL_Video_Compression"  # Linux/Mac
$env:PYTHONPATH = "D:\path\to\RL_Video_Compression"  # Windows
```

**Experiment 2: Random Policy** (with checkpoint resume):
```bash
python scripts/evaluate_random_policy.py
# Auto-resumes from checkpoint if interrupted
# Output: outputs/random_policy_results.csv (840 rows)
```

**Experiment 3: RL Agent**:
```bash
python scripts/evaluate_rl_agent.py
# Output: outputs/rl_agent_results.csv (280 rows)
```

**Experiment 4: Statistical Tests**:
```bash
python scripts/statistical_tests.py
# Compares RL vs Fixed B=10, generates significance tests
# Output: outputs/statistical_tests_results.json
```

**Create Experiment Package** (for distributed execution):
```bash
.\create_experiment_package.ps1
# Creates experiment_3_4_package.zip with all dependencies
# Transfer to another computer and run Exp 3-4 in parallel
```

### Generate Dataset

```bash
python scripts/generate_full_dataset.py
```

### Train YOLOv8

```bash
cd training
python train_yolo_local.py  # Auto-resumes from checkpoint if exists
```

### Validate Model

```bash
cd training
python validate_yolo.py
```

### Check Progress

```bash
python scripts/check_dataset_progress.py
```

---

## ğŸ¯ Research Objectives

1. âœ… **Dataset Generation**: Create SCI compressed measurements from CURE-TSD (28,727 images)
2. âœ… **YOLO Fine-tuning**: Train detector on compressed data (83.29% mAP50)
3. âœ… **RL Agent Training**: DQN agent for adaptive B-selection (500 episodes, +9.0%)
4. ğŸ”„ **Benchmarking**: Full evaluation on 280 validation videos
   - âœ… Experiment 1: Fixed baselines complete
   - ğŸ”„ Experiment 2: Random policy running
   - â³ Experiment 3: RL agent queued
   - â³ Experiment 4: Statistical analysis queued
5. ğŸ“‹ **Paper Writing**: Document methodology, results, and analysis

**Progress**: ~85% complete (benchmarking in progress)

---

## ğŸ“ˆ Expected Impact

- **Bandwidth Savings**: 15-20% vs fixed compression schemes
- **Detection Accuracy**: Near-optimal (within 5% of uncompressed)
- **Real-time Capable**: Adaptive selection <33ms latency
- **Safety-Aware**: Prioritizes critical sign detection

---

## ğŸ“š Key References

1. CURE-TSD Dataset: [Temel et al. (2017)](https://github.com/olivesgatech/CURE-TSD)
2. YOLOv8: [Ultralytics (2023)](https://github.com/ultralytics/ultralytics)
3. Snapshot Compressive Imaging: [Yuan et al. (2016)](https://opg.optica.org/oe/fulltext.cfm?uri=oe-24-17-18829)
4. Deep Q-Network: [Mnih et al. (2015)](https://www.nature.com/articles/nature14236)

---

## ğŸ› Troubleshooting

### CUDA Out of Memory
```python
# Reduce batch size in train_yolo_local.py
'batch': 8,  # Default is 16
```

### Dataset Not Found
```bash
# Verify data.yaml path
data: ../data/yolo_dataset_full/data.yaml
```

### Training Not Resuming
```bash
# Check checkpoint exists
ls ../runs/train/yolo_cure_tsd/weights/last.pt
```

---

## ğŸ‘¥ Authors

**Manveer Anand**  
CS307 - Advanced Topics in Computer Vision  
[GitHub](https://github.com/ManveerAnand/Adaptive_video_compression)

---

## ğŸ“ License

MIT License - See LICENSE for details

---

## ğŸ”— Links

- **Documentation**: [docs/PROJECT_STATUS.md](docs/PROJECT_STATUS.md)
- **Repository**: [github.com/ManveerAnand/Adaptive_video_compression](https://github.com/ManveerAnand/Adaptive_video_compression)

---

**Last Updated**: November 15, 2025  
**Status**: ğŸ”„ **Benchmarking In Progress** - Exp 1 complete (1682 results), Exp 2-4 running
